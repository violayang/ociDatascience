{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cbb6b4",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85b2a0",
   "metadata": {},
   "source": [
    "# Train and Deploy Transfomer Model using ADS\n",
    "\n",
    "** conda: pytorch110_p38_gpu_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c375b",
   "metadata": {},
   "source": [
    "### Install and upgrade required packages - one time for conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82573991",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oracle-ads in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (2.6.8)\n",
      "Collecting oracle-ads\n",
      "  Using cached oracle_ads-2.8.3-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: requests in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (4.64.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.8.10)\n",
      "Requirement already satisfied: numpy>=1.19.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.23.3)\n",
      "Requirement already satisfied: cloudpickle>=1.6.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (2.0.0)\n",
      "Requirement already satisfied: ocifs>=1.1.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.1.3)\n",
      "Requirement already satisfied: python-jsonschema-objects>=0.3.13 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.4.1)\n",
      "Requirement already satisfied: PyYAML<6,>=5.4 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (5.4.1)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (5.9.0)\n",
      "Requirement already satisfied: pandas<1.6,>1.2.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.4.4)\n",
      "Collecting oci>=2.96.0\n",
      "  Using cached oci-2.97.0-py3-none-any.whl (20.1 MB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.1.2)\n",
      "Requirement already satisfied: cerberus>=1.3.4 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.3.4)\n",
      "Requirement already satisfied: fsspec>=0.8.7 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (2022.7.1)\n",
      "Requirement already satisfied: asteval>=0.9.25 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (0.9.27)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.5.2)\n",
      "Requirement already satisfied: gitpython>=3.1.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (3.1.18)\n",
      "Requirement already satisfied: scikit-learn<1.2,>=0.23.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oracle-ads) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from cerberus>=1.3.4->oracle-ads) (65.5.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from gitpython>=3.1.2->oracle-ads) (4.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from jinja2>=2.11.2->oracle-ads) (2.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (4.38.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from matplotlib>=3.1.3->oracle-ads) (2.8.2)\n",
      "Requirement already satisfied: certifi in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oci>=2.96.0->oracle-ads) (2022.9.24)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=17.5.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oci>=2.96.0->oracle-ads) (22.0.0)\n",
      "Requirement already satisfied: pytz>=2016.10 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oci>=2.96.0->oracle-ads) (2022.6)\n",
      "Requirement already satisfied: circuitbreaker<2.0.0,>=1.3.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oci>=2.96.0->oracle-ads) (1.4.0)\n",
      "Requirement already satisfied: cryptography<40.0.0,>=3.2.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from oci>=2.96.0->oracle-ads) (37.0.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (1.16.0)\n",
      "Requirement already satisfied: Markdown>=2.4 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (3.4.1)\n",
      "Requirement already satisfied: jsonschema>=2.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (4.17.0)\n",
      "Requirement already satisfied: inflection>=0.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-jsonschema-objects>=0.3.13->oracle-ads) (0.5.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.23.2->oracle-ads) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->oracle-ads) (2.1.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from cryptography<40.0.0,>=3.2.1->oci>=2.96.0->oracle-ads) (1.14.6)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.2->oracle-ads) (3.0.5)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (5.10.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (0.19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from jsonschema>=2.3->python-jsonschema-objects>=0.3.13->oracle-ads) (22.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from Markdown>=2.4->python-jsonschema-objects>=0.3.13->oracle-ads) (5.0.0)\n",
      "Requirement already satisfied: pycparser in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from cffi>=1.12->cryptography<40.0.0,>=3.2.1->oci>=2.96.0->oracle-ads) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from importlib-metadata>=4.4->Markdown>=2.4->python-jsonschema-objects>=0.3.13->oracle-ads) (3.10.0)\n",
      "Installing collected packages: oci, oracle-ads\n",
      "  Attempting uninstall: oci\n",
      "    Found existing installation: oci 2.88.0\n",
      "    Uninstalling oci-2.88.0:\n",
      "      Successfully uninstalled oci-2.88.0\n",
      "  Attempting uninstall: oracle-ads\n",
      "    Found existing installation: oracle-ads 2.6.8\n",
      "    Uninstalling oracle-ads-2.6.8:\n",
      "      Successfully uninstalled oracle-ads-2.6.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "oci-cli 3.20.1 requires oci==2.88.0, but you have oci 2.97.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed oci-2.97.0 oracle-ads-2.8.3\n"
     ]
    }
   ],
   "source": [
    "# Upgrade Oracle ADS to pick up latest features and maintain compatibility with Oracle Cloud Infrastructure.\n",
    "!pip install --upgrade oracle-ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dc4bcc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (4.24.0)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: requests in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from transformers) (1.23.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.24.0\n",
      "    Uninstalling transformers-4.24.0:\n",
      "      Successfully uninstalled transformers-4.24.0\n",
      "Successfully installed huggingface-hub-0.13.3 transformers-4.27.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "803cd789",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg-python\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=14eac3712ace7eec00b22c4db31f8324879f55003ae78bdbb0850471ca53c35c\n",
      "  Stored in directory: /home/datascience/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
      "Successfully built future\n",
      "Installing collected packages: future, ffmpeg-python\n",
      "Successfully installed ffmpeg-python-0.2.0 future-0.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24805240",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Cloning https://github.com/huggingface/datasets to /tmp/pip-install-pl_4ff3k/datasets_1d0fc172e62f4598919209fbbf201c8d\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/datasets /tmp/pip-install-pl_4ff3k/datasets_1d0fc172e62f4598919209fbbf201c8d\n",
      "  Resolved https://github.com/huggingface/datasets to commit 0803a006db1c395ac715662cc6079651f77c11ea\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: packaging in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (1.23.3)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-11.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.0 MB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pandas in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (1.4.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (0.13.3)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Requirement already satisfied: aiohttp in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Building wheels for collected packages: datasets\n",
      "  Building wheel for datasets (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for datasets: filename=datasets-2.11.1.dev0-py3-none-any.whl size=468875 sha256=1522b53956750db0f1d9743dc036d41b15342924138292abe4441416a55b86ac\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_i8mqsj9/wheels/fa/94/e3/3c713e74271e453a93a303d5095aca41e03828d80af1b3742c\n",
      "Successfully built datasets\n",
      "Installing collected packages: xxhash, pyarrow, dill, responses, multiprocess, datasets\n",
      "Successfully installed datasets-2.11.1.dev0 dill-0.3.6 multiprocess-0.70.14 pyarrow-11.0.0 responses-0.18.0 xxhash-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/datasets#egg=datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6892186",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (0.13.3)\n",
      "Requirement already satisfied: packaging in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (21.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (2.11.1.dev0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (2022.7.1)\n",
      "Requirement already satisfied: xxhash in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (1.23.3)\n",
      "Requirement already satisfied: pandas in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: multiprocess in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: dill in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from pandas->evaluate) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa9c5905",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting rouge_score\n",
      "  Using cached rouge_score-0.1.2-py3-none-any.whl\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from rouge_score) (1.23.3)\n",
      "Requirement already satisfied: absl-py in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from rouge_score) (1.3.0)\n",
      "Requirement already satisfied: joblib in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: click in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from nltk->rouge_score) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from nltk->rouge_score) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from nltk->rouge_score) (4.64.1)\n",
      "Installing collected packages: nltk, rouge_score\n",
      "Successfully installed nltk-3.8.1 rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f4e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pyarrow==6.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b5ffa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages (from pyarrow) (1.23.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc041791",
   "metadata": {},
   "source": [
    "# Build Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0f0e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0.0\n"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "print(pyarrow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c8d232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ads\n",
    "ads.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6b5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3333a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6474f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import ads\n",
    "import time\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "import transformers\n",
    "from transformers.onnx import FeaturesManager\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bcfecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.set_auth(\"api_key\", profile=\"jiayuan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef5a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcd82e3d75d476fa5871fba361721b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f771385c94824e00a7d4ea7b6eff6f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8012c5aa0fc240878214dffe6a7066e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset billsum/default (download: 64.14 MiB, generated: 259.79 MiB, post-processed: Unknown size, total: 323.93 MiB) to /home/datascience/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5778ed041d04227998723e74d1e7f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/67.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/18949 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating ca_test split:   0%|          | 0/1237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset billsum downloaded and prepared to /home/datascience/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "billsum = load_dataset(\"billsum\", split=\"ca_test\", download_mode=\"force_redownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5a6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885b93fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The people of the State of California do enact as follows:\n",
      "\n",
      "\n",
      "SECTION 1.\n",
      "(a) The Legislature finds and declares all of the following:\n",
      "(1) According to data released by the\n",
      "U.S.\n",
      "United States\n",
      "Census Bureau, without a high school diploma, Americans are almost twice as likely to live in poverty.\n",
      "(2) Several independent academic studies indicate a marked increase in school participation and graduation rates among children who were guaranteed transportation to and from school.\n",
      "(3) According to a recent report by\n",
      "California\n",
      "Attorney General Kamala Harris, poverty and financial instability is the number one cause of truancy in the state.\n",
      "(4) Research shows a strong relationship between access to transportation and improved school attendance.\n",
      "(b) Based on the findings and declarations in subdivision (a), it is the intent of the Legislature to enact legislation that would support school participation and high school attainment among low-income youth.\n",
      "SEC. 2.\n",
      "Section 39800 of the Education Code is amended to read:\n",
      "39800.\n",
      "(a) In addition to the requirement to provide transportation pursuant to Section 39800.1, the governing board of any school district may provide for the transportation of pupils to and from school whenever, in the judgment of the governing board, the transportation is advisable and good reasons exist. The governing board of a school district may purchase or rent and provide for the upkeep, care, and operation of\n",
      "vehicles, or\n",
      "vehicles. The governing board of a school district\n",
      "may\n",
      "also\n",
      "contract and pay for the transportation of middle school and high school pupils to and from school by a vehicle driven by a public employee of a municipally owned transit system, or may contract with the parent or guardian of the pupil being transported. The governing board of a school district may allow the transportation of preschool or nursery school pupils in schoolbuses owned or operated by the school district. A state reimbursement may not be received by a school district for the transportation of preschool or nursery school pupils.\n",
      "(b) As used in this article, “municipally owned transit system” means a transit system owned by a city or by a district created under Part 1 (commencing with Section 24501) of Division 10 of the Public Utilities Code.\n",
      "SEC. 3.\n",
      "Section 39800.1 is added to the Education Code, to read:\n",
      "39800.1.\n",
      "(a) Notwithstanding any other law, a pupil attending a public, noncharter school that\n",
      "is eligible for\n",
      "receives\n",
      "Title 1 federal funding shall be entitled to free transportation to and from school, if either of the following conditions are met:\n",
      "(1) The pupil resides more than one-half mile from the school.\n",
      "(2) The neighborhood through which the pupil must travel to get to school is unsafe, as defined by the plan established pursuant to paragraph (1) of subdivision (b), which may include factors, including, but not limited to, stray dogs, lack of sidewalks, known gang activity, presence of environmental problems and hazards, required crossings of freeways or busy intersections, or other reasons documented by stakeholders in the plan developed pursuant to subdivision (c).\n",
      "(b) (1) A school district not currently providing transportation to all pupils attending schools that\n",
      "are eligible for\n",
      "receive\n",
      "Title 1 federal funding shall implement a plan to ensure that all pupils entitled to free transportation pursuant to subdivision (a) receive the transportation.\n",
      "(2) The plan shall identify and accommodate the special rights of homeless youth, as defined pursuant to the federal McKinney-Vento Homeless Assistance Act (42 U.S.C. Sec. 11301 et seq.).\n",
      "(c) The plan required by paragraph (1) of subdivision (b) shall be developed with the consultation of teachers, school administrators, regional local transit authorities, local air districts, the Department of Transportation, parents, pupils, and other stakeholders.\n",
      "(d) If free, dependable, and timely transportation is not already available to pupils entitled to transportation services pursuant to this section, the school district shall ensure that the pupils entitled to the transportation are provided free transportation.\n",
      "(e) Notwithstanding subdivision (f), transportation provided pursuant to this section shall be provided by a public employee.\n",
      "(f) A school district may partner with a\n",
      "transit authority\n",
      "municipality owned transit system\n",
      "to provide the transportation provided pursuant to this section to middle school and high school pupils if all of the following conditions are met:\n",
      "(1) All drivers are public employees of a municipality owned transit\n",
      "agency\n",
      "system\n",
      "as defined in subdivision (b) of Section 39800.\n",
      "(2) The\n",
      "municipality owned\n",
      "transit\n",
      "agency\n",
      "system\n",
      "can certify that the\n",
      "public\n",
      "transit system can ensure consistent, adequate routes and schedules to enable pupils to get home, to school and back, and does not charge the school district more than marginal cost for each transit pass.\n",
      "(3) Nothing in this section would prevent a local transportation agency from providing no-cost transit passes to pupils attending Title 1 schools.\n",
      "(g) All transportation provided pursuant to this section shall be reimbursed by the Transportation and Access to Public School Fund created pursuant to Section 39800.2.\n",
      "SEC. 4.\n",
      "Section 39800.2 is added to the Education Code, to read:\n",
      "39800.2.\n",
      "(a) The Transportation and Access to Public School Fund is hereby created in the State Treasury to be administered by the department.\n",
      "(b) Funds in the Transportation and Access to Public School Fund shall, upon appropriation by the Legislature, be allocated to the department for allocation to local educational agencies pursuant to the process established by the Superintendent.\n",
      "(c) Commencing with the 2017–18 fiscal year, the Superintendent shall allocate from the Transportation and Access to Public School Fund to each school district, county office of education, entity providing services under a school transportation joint powers agreement, or regional occupational center or program that provides pupil transportation an amount equal to the actual costs of the entitled transportation established pursuant to Section 39800.1. The allocation shall be in addition to any amount apportioned for home-to-school transportation pursuant to Article 10 (commencing with Section 41850) of Chapter 5 of Part 24.\n",
      "(d) This section shall become operative only to the extent that funding is provided in the annual Budget Act or another statute for the purposes of this section.\n",
      "SEC. 5.\n",
      "If the Commission on State Mandates determines that this act contains costs mandated by the state, reimbursement to local agencies and school districts for those costs shall be made pursuant to Part 7 (commencing with Section 17500) of Division 4 of Title 2 of the Government Code.\n"
     ]
    }
   ],
   "source": [
    "print(billsum[\"train\"][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ed9809",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) The Mental Health Services Act (MHSA), an initiative measure enacted by the voters as Proposition 63 at the November 2, 2004, statewide general election, imposes a 1% tax on that portion of a taxpayer’s taxable income that exceeds $1,000,000 and requires that the revenue from that tax be deposited in the Mental Health Services Fund to fund various county mental health programs. The MHSA authorizes the Legislature to amend its provisions by a\n",
      "2/3\n",
      "vote, provided that the amendment is consistent with and furthers the intent of the act.\n",
      "Existing law, known as the No Place Like Home Program, requires the Department of Housing and Community Development to award $2,000,000,000 among counties to finance capital costs, including, but not limited to, acquisition, design, construction, rehabilitation, or preservation, and to capitalize operating reserves, of permanent supportive housing for the target population, as specified. Existing law requires the department to distribute $1,800,000,000 through a competitive program and to allocate $200,000,000 among all counties within this state on an “over-the-counter” population basis.\n",
      "The bill would authorize the California Health Facilities Financing Authority and the department to, among other things, enter into contracts to provide services pursuant to the No Place Like Home Program related to permanent supportive housing. The bill would also authorize the authority to issue taxable or tax-exempt revenue bonds in an amount not to exceed $2,000,000,000 for these purposes and to make secured or unsecured loans to the department in connection with financing permanent supportive housing pursuant to the No Place Like Home Program. The bill would require that the dollar limit on amounts distributed under the No Place Like Home Program be based on the principal amount of bonds issued by the authority and loaned to the department.\n",
      "The bill would additionally authorize the use of moneys in the Mental Health Services Fund for the purposes of the No Place Like Home Program. The bill would also establish and continuously appropriate the Supportive Housing Program Subaccount in the Mental Health Services Fund. The bill would require the Controller, no later than the last day of each month and prior to any transfer or expenditure from the fund for any other purpose for the following month, to transfer from the Mental Health Services Fund to the Supportive Housing Program Subaccount an amount necessary to cover the costs the authority is required to pay to the department pursuant to an above-described service contract, as determined by the authority but not to exceed an aggregate amount of $140,000,000 per year. The bill would prohibit moneys in the Supportive Housing Program Subaccount from being loaned to the General Fund pursuant to specified statutes.\n",
      "The bill would exempt service contracts between the department and the authority pursuant to these provisions from specified public contracting laws. The bill would also exempt loan agreements between the department and the authority and revenue bonds issued by the authority from any other law applicable to the execution of those agreements or issuance of those bonds, including the California Environmental Quality Act.\n",
      "(2) Existing law establishes the No Place Like Home Fund and continuously appropriates the moneys in this fund to the Department of Housing and Community Development for the purposes of the No Place Like Home Program. Existing law requires the deposit into the fund of, among other moneys, any proceeds from the issuance of bonds by the Treasurer.\n",
      "This bill would instead require the department to deposit into the fund the proceeds of loans derived from the issuance of bonds under this bill by the California Health Facilities Financing Authority. The bill would additionally continuously appropriate moneys in the fund to the Treasurer and the authority for purposes of the No Place Like Home Program.\n",
      "(3) Existing law requires counties to annually report specified information to the Department of Housing and Community Development on activities funded under the No Place Like Home Program, including information on the funded supportive housing development. Existing law also requires the department to report specified information on the program to the Legislature by December 31 of each year, commencing with the year after the first full year in which the program is in effect.\n",
      "This bill would require the department to monitor county compliance with applicable program regulations, loan agreements and regulatory agreements and any agreements related to the program that designate the department as a 3rd party beneficiary, and enforce those agreements to the extent necessary and desirable in order to provide, to the greatest degree possible, the successful provision of permanent supportive housing. The bill would require the department to submit a report to the California Health Facilities Financing Authority by December 31 of each year, commencing with the year after the first full year in which the program is in effect, that contains specified information about the counties participating in the program and the services that have been provided pursuant to any service contracts between the department and the authority, as described above.\n",
      "(4) Existing law establishes a procedure by which a public agency may bring an action in the superior court to determine the validity of any matter authorized by other law. Existing law authorizes an action under this procedure to determine the legality of any action by the Department of Housing and Community Development related to the No Place Like Home Program. Existing law requires the department to issue its first request for proposal for the competitive program no later than 180 days, and to make its first allocation of “over-the-counter” funds within 60 days, after the deadline for appeals under the validation procedure.\n",
      "This bill would recast this authorization to instead authorize an action to determine the validity of any service contract or loan agreement between the department and the California Health Facilities Financing Authority, as described above, in accordance with specified provisions governing actions to determine the validity of bonds, warrants, contracts, obligations, or evidences of indebtedness. The bill would instead require the department to issue its first request for proposal no later than 180 days, and to make its first allocation of “over-the-counter” funds as soon as reasonably practical, but no later than 150 days, after the effective date of a final judgment with no further opportunity for appeals, in any court proceeding affirming the validity of the service contracts between the department and the authority and any bonds issued by the authority.\n",
      "(5) Existing law authorizes the Department of Finance to authorize a loan from the General Fund to the No Place Like Home Fund for cashflow purposes in an amount not to exceed $1,000,000. Existing law requires that a loan comply with certain requirements, including that the purpose of the loan is to allow the department to begin implementation activities related to the No Place Like Home Program, including drafting program guidelines and regulations.\n",
      "This bill would instead authorize the Department of Finance to authorize one or more loans from the General Fund to the No Place Like Home Fund in an aggregate amount not to exceed $2,000,000. The bill would additionally authorize loans for the purpose of allowing the Department of Housing and Community Development, the California Health Facilities Financing Authority, and the Treasurer to implement the above-described provisions pertaining to service contracts and loan agreements between the department and the authority and revenue bonds issued by the authority.\n",
      "(6) Existing law makes various findings and declarations regarding the No Place Like Home Program.\n",
      "This bill would make additional findings and declarations pertaining to the financing and implementation of the No Place Like Home Program. The bill would also make various technical and conforming changes to the No Place Like Home Program.\n",
      "(7) This bill would declare that its provisions further the intent of the MHSA.\n",
      "(8) This bill would declare that it is to take effect immediately as a bill providing for appropriations related to the Budget Bill.\n"
     ]
    }
   ],
   "source": [
    "print(billsum[\"train\"][0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc77dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An act to add Section 15463 to the Government Code, and to amend Sections 5849.1, 5849.2, 5849.3, 5849.4, 5849.5, 5849.7, 5849.8, 5849.9, 5849.11, 5849.14, 5890, and 5891 of, to add Section 5849.35 to, and to repeal and add Section 5849.13 of, the Welfare and Institutions Code, relating to mental health services, and making an appropriation therefor, to take effect immediately, bill related to the budget.\n"
     ]
    }
   ],
   "source": [
    "print(billsum[\"train\"][0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba3386c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc96d70939e400daa9a978caa4746a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5062dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3066be4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_billsum = billsum.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a806b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e37e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05261e8b",
   "metadata": {},
   "source": [
    "# Train with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df4dbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c158219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTrainingArguments(output_dir='pytorch_model', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.EPOCH: 'epoch'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=2e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=4, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level='passive', log_level_replica='warning', log_on_each_node=True, logging_dir='pytorch_model/runs/May09_16-57-58_bca136a74ae7', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=3, save_on_each_node=False, no_cuda=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=True, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=None, dataloader_num_workers=0, past_index=-1, run_name='pytorch_model', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_HF: 'adamw_hf'>, optim_args=None, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=False, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, torch_compile=False, torch_compile_backend=None, torch_compile_mode=None, sortish_sampler=False, predict_with_generate=True, generation_max_length=None, generation_num_beams=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameter, define output directory of saved model to local, do not push to online hub \n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"pytorch_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,      ##----- only enable if running on gpu\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c05c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e54a1439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/datascience/conda/pytorch110_p38_gpu_v1/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 05:59, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.508366</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.924900</td>\n",
       "      <td>2.421140</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.558300</td>\n",
       "      <td>2.382504</td>\n",
       "      <td>0.194300</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.480000</td>\n",
       "      <td>2.374255</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# finetune the model\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b7a92cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 360.1333200931549 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d32ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d0a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_billsum[\"test\"].head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edaa0cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[    0, 17061,    53, ...,    45,     8, 21104],\n",
       "       [    0, 17061,    53, ...,     8,   158,  4370],\n",
       "       [    0, 17061,    53, ...,     3,    99,    34],\n",
       "       ...,\n",
       "       [    0, 17061,    53, ...,    12,   136,   568],\n",
       "       [    0, 17061,    53, ...,    24,     3, 12436],\n",
       "       [    0, 17061,    53, ...,     8,  6537,    13]]), label_ids=array([[17061,    53,   973, ...,   169,  5161,     1],\n",
       "       [17061,    53,   973, ...,    15,    26,     1],\n",
       "       [   37,  1826,  9185, ...,   353,    19,     1],\n",
       "       ...,\n",
       "       [ 5637,    37,  1826, ...,   442,   452,     1],\n",
       "       [17061,    53,   973, ...,  7864,  7173,     1],\n",
       "       [17061,    53,   973, ...,  2350,    11,     1]]), metrics={'test_loss': 2.3742551803588867, 'test_rouge1': 0.1941, 'test_rouge2': 0.092, 'test_rougeL': 0.1641, 'test_rougeLsum': 0.1642, 'test_gen_len': 19.0, 'test_runtime': 33.7413, 'test_samples_per_second': 7.35, 'test_steps_per_second': 3.675})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(tokenized_billsum[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8857b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_local = AutoModelForSeq2SeqLM.from_pretrained(\"/home/datascience/Jiayuan/NCH/pytorch_model/checkpoint-1500\")\n",
    "tokenizer_local = AutoTokenizer.from_pretrained(\"/home/datascience/Jiayuan/NCH/pytorch_model/checkpoint-1500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d64dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenizer_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e22c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc8795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57514050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a935b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72d6705b",
   "metadata": {},
   "source": [
    "# Inference use transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163ab593",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f01caba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text2text_generation.SummarizationPipeline"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer_finetune = pipeline(\"summarization\", model=\"/home/datascience/Jiayuan/NCH/pytorch_model/checkpoint-1500\")\n",
    "type(summarizer_finetune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9953f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load pipeline using pre-built model\n",
    "\n",
    "# summarizer = pipeline(\"summarization\", model=model, tokenizer = tokenizer)\n",
    "# summarizer(text, max_length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102f80a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'a newspaper would be produced by a web-perfecting press, capable of producing 25,000 impressions an hour, instead of the old hand press of 240 impressions an hour, and the mailing machine, enabling one man to do the work of five or six under the old method. The Sunday Pioneer Press would take 600 hand presses, 600 hand pressmen and 600 boys three hours to print the edition, and as there were no means of stereotyping in those days the forms would have to be set up 600 times, requiring the services of 25,000 impressions an hour, and the linotype, instead of the old hand press of 240 impressions an hour, and the linotype machine, and the mailing machine, and the linotype machine, and the linotype, and the .'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph1 = \"\"\"If James M. Goodhue could revisit the earth and make a tour among the\n",
    "daily newspaper offices of St. Paul he would discover that wonderful\n",
    "strides had been made in the method of producing a newspaper during\n",
    "the latter half of the past century. Among the first things to attract\n",
    "the attention of this old-timer would be the web-perfecting press,\n",
    "capable of producing 25,000 impressions an hour, instead of the old\n",
    "hand press of 240 impressions an hour; the linotype machine, capable\n",
    "of setting 6,000 to 10,000 ems per hour, instead of the old hand\n",
    "compositor producing only 800 to 1,000 ems per hour, and the mailing\n",
    "machine, enabling one man to do the work of five or six under the\n",
    "old method. Think of getting out the Sunday Pioneer Press with the\n",
    "material in use fifty years ago. It would take 600 hand presses, 600\n",
    "hand pressmen and 600 boys three hours to print the edition, and as\n",
    "there were no means of stereotyping in those days the forms would have\n",
    "to be set up 600 times, requiring the services of 5,000 compositors.\n",
    "Papers printed under these conditions would have to be sold for one\n",
    "dollar each, and there would not be much profit in it at that. The\n",
    "first daily papers printed in St. Paul were not conducted or a very\n",
    "gigantic scale, as the entire force of one office generally consisted\n",
    "of one pressman, five or six compositors, two editors and a business\n",
    "manager. A few reminiscences of the trials and tribulations of the\n",
    "early newspaper manager, editor and compositor may not be wholly\n",
    "devoid of interest.\n",
    "\"\"\"\n",
    "\n",
    "summarizer_finetune(paragraph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48f125de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"The Gray Eagle and Itasca were expected to bring the news of the successful laying of the cable, and the itasca started from Dubuque at 9 o'clock in the morning and the Itasca started from Prairie du Chien\"}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "In 1858, when the first Atlantic cable was laid, the news was\n",
    "anxiously looked for, and nearly every inhabitant of the city turned\n",
    "out to greet the arrival of the Gray Eagle and Itasca, two of the\n",
    "fastest boats on the river, which were expected to bring the news\n",
    "of the successful laying of the cable. The Gray Eagle started from\n",
    "Dubuque at 9 o'clock in the morning and the Itasca started from\n",
    "Prairie du Chien, about 100 miles farther up the river, at noon of the\n",
    "same day. When the boats reached the bend below the river they were\n",
    "abreast of each other, and as they reached the levee it was hardly\n",
    "possible to tell which was ahead. One of the passengers on the Gray\n",
    "Eagle had a copy of the Dubuque Herald containing the Queen's message,\n",
    "tied up with a small stone on the inside of it, and as he threw it to\n",
    "the shore a messenger from the Minnesotian caught it and ran up Bench\n",
    "street to the Minnesotian office, where the printers were waiting,\n",
    "and the Minnesotian had the satisfaction of getting out an extra some\n",
    "little time before their competitors.In the summer season the newspapers had to rely, to a considerable\n",
    "extent, on the steamboats for late Dubuque and Chicago papers for\n",
    "telegraph news. There were three or four daily lines of steamers to\n",
    "St. Paul, and every one of them could be distinguished by its whistle.\n",
    "When it was time for the arrival of the boat bringing the newspapers\n",
    "from which the different papers expected to get their telegraphic\n",
    "news, messengers from the different offices would be at the levee, and\n",
    "as the boat neared the shore they would leap for the gangplank, and\n",
    "there was always a scramble to get to the clerk's office first.\n",
    "James J. Hill and the late Gus Borup were almost always at the levee\n",
    "awaiting the arrival of the steamers, but as they were after copies\n",
    "of the boats' manifest they did not come in competition with the\n",
    "adventurous kids from the newspaper offices.\"\"\"\n",
    "\n",
    "summary_text = summarizer_finetune(text, max_length = 50)\n",
    "summary_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d2e1b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zoom interface is really simple and easy to conduct virtual meetings. It is very easy to share the Zoom link to join the video conference. And overall screen sharing quality is ok. Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores , for its cloud infrastructure deployments over the likes of Amazon, Microsoft, Google, and even IBM to build an enterprise grade experience for its product.\n",
      "\n",
      "summary text: \n",
      " [{'summary_text': 'Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores .'}]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Zoom interface is really simple and easy to conduct virtual meetings. It is very easy to share the Zoom link to join the video conference. And overall screen sharing quality is ok. Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores , for its cloud infrastructure deployments over the likes of Amazon, Microsoft, Google, and even IBM to build an enterprise grade experience for its product.\n",
    "\"\"\"\n",
    "print(text)\n",
    "print('summary text: \\n', summarizer_finetune(text, max_length = 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d831cda5",
   "metadata": {},
   "source": [
    "# Prepare Tranformer Model using ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f287b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ads.common.model_metadata import UseCaseType\n",
    "from ads.model import HuggingFacePipelineModel\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a2383a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "algorithm: SummarizationPipeline\n",
       "artifact_dir:\n",
       "  /home/datascience/Jiayuan/NCH/t5_model_artifact:\n",
       "  - - tokenizer.json\n",
       "    - .model-ignore\n",
       "    - config.json\n",
       "    - generation_config.json\n",
       "    - score.py\n",
       "    - special_tokens_map.json\n",
       "    - tokenizer_config.json\n",
       "    - pytorch_model.bin\n",
       "    - runtime.yaml\n",
       "framework: transformers\n",
       "model_deployment_id: null\n",
       "model_id: null"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the model\n",
    "\n",
    "artifact_dir = \"t5_model_artifact\"\n",
    "## Initiate a HuggingFacePipelineModel instance\n",
    "huggingface_pipeline_model = HuggingFacePipelineModel(summarizer_finetune, artifact_dir=artifact_dir)    # model == pipeline\n",
    "## Prepare\n",
    "huggingface_pipeline_model.prepare(\n",
    "    inference_conda_env=\"oci://conda_env@orasenatdpltintegration03/conda_environments/gpu/PyTorch 1.10 for GPU on Python 3.8/1.0/pytorch110_p38_gpu_v1\",      # custom conda\n",
    "    inference_python_version=\"3.8\",\n",
    "    training_conda_env=\"oci://conda_env@orasenatdpltintegration03/conda_environments/gpu/PyTorch 1.10 for GPU on Python 3.8/1.0/pytorch110_p38_gpu_v1\",\n",
    "    use_case_type=UseCaseType.OTHER,\n",
    "    force_overwrite=True,\n",
    "    training_script_path=\"/home/datascience/Jiayuan/NCH/Train&DeployTransformerModel.ipynb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea345b8",
   "metadata": {},
   "source": [
    "# Summary Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22ea2899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Actions Needed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Step</th>\n",
       "      <th>Status</th>\n",
       "      <th>Details</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>initiate</th>\n",
       "      <th>Done</th>\n",
       "      <th>Initiated the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">prepare()</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">Done</th>\n",
       "      <th>Generated runtime.yaml</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Generated score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serialized model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Populated metadata(Custom, Taxonomy and Provenance)</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify()</th>\n",
       "      <th>Available</th>\n",
       "      <th>Local tested .predict from score.py</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">save()</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Available</th>\n",
       "      <th>Conducted Introspect Test</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uploaded artifact to model catalog</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deploy()</th>\n",
       "      <th>UNKNOWN</th>\n",
       "      <th>Deployed the model</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict()</th>\n",
       "      <th>Not Available</th>\n",
       "      <th>Called deployment predict endpoint</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Actions Needed\n",
       "Step      Status        Details                                                           \n",
       "initiate  Done          Initiated the model                                               \n",
       "prepare() Done          Generated runtime.yaml                                            \n",
       "                        Generated score.py                                                \n",
       "                        Serialized model                                                  \n",
       "                        Populated metadata(Custom, Taxonomy and Provenance)               \n",
       "verify()  Available     Local tested .predict from score.py                               \n",
       "save()    Available     Conducted Introspect Test                                         \n",
       "                        Uploaded artifact to model catalog                                \n",
       "deploy()  UNKNOWN       Deployed the model                                                \n",
       "predict() Not Available Called deployment predict endpoint                                "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipeline_model.summary_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbf0cf",
   "metadata": {},
   "source": [
    "### verify local model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25668d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'summary_text': 'a newspaper would be produced by a web-perfecting press, capable of producing 25,000 impressions an hour, instead of the old hand press of 240 impressions an hour, and the mailing machine, enabling one man to do the work of five or six under the old method. The Sunday Pioneer Press would take 600 hand presses, 600 hand pressmen and 600 boys three hours to print the edition, and as there were no means of stereotyping in those days the forms would have to be set up 600 times, requiring the services of 25,000 impressions an hour, and the linotype, instead of the old hand press of 240 impressions an hour, and the linotype machine, and the mailing machine, and the linotype machine, and the linotype, and the .'}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from t5_model_artifact import score\n",
    "\n",
    "text = \"\"\"\n",
    "If James M. Goodhue could revisit the earth and make a tour among the\n",
    "daily newspaper offices of St. Paul he would discover that wonderful\n",
    "strides had been made in the method of producing a newspaper during\n",
    "the latter half of the past century. Among the first things to attract\n",
    "the attention of this old-timer would be the web-perfecting press,\n",
    "capable of producing 25,000 impressions an hour, instead of the old\n",
    "hand press of 240 impressions an hour; the linotype machine, capable\n",
    "of setting 6,000 to 10,000 ems per hour, instead of the old hand\n",
    "compositor producing only 800 to 1,000 ems per hour, and the mailing\n",
    "machine, enabling one man to do the work of five or six under the\n",
    "old method. Think of getting out the Sunday Pioneer Press with the\n",
    "material in use fifty years ago. It would take 600 hand presses, 600\n",
    "hand pressmen and 600 boys three hours to print the edition, and as\n",
    "there were no means of stereotyping in those days the forms would have\n",
    "to be set up 600 times, requiring the services of 5,000 compositors.\n",
    "Papers printed under these conditions would have to be sold for one\n",
    "dollar each, and there would not be much profit in it at that. The\n",
    "first daily papers printed in St. Paul were not conducted or a very\n",
    "gigantic scale, as the entire force of one office generally consisted\n",
    "of one pressman, five or six compositors, two editors and a business\n",
    "manager. A few reminiscences of the trials and tribulations of the\n",
    "early newspaper manager, editor and compositor may not be wholly\n",
    "devoid of interest.\"\"\"\n",
    "\n",
    "score.predict(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13773d69",
   "metadata": {},
   "source": [
    "# Register Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cca95276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is successfully loaded.\n",
      "['tokenizer.json', '.model-ignore', 'config.json', 'generation_config.json', 'score.py', 'special_tokens_map.json', 'tokenizer_config.json', 'pytorch_model.bin', 'runtime.yaml', 'test_json_output.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Register the model\n",
    "model_id = huggingface_pipeline_model.save(\n",
    "    display_name=\"transformer_t5\",\n",
    "    model_version_set=\"ocid1.datasciencemodelversionset.oc1.iad.amaaaaaawe6j4fqawzqitdpwhetgkxcwmph6rv7jhc7hvk3p4wr3qk6fmcja\"   # model version transformer-t5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541b7213",
   "metadata": {},
   "source": [
    "# Deploy Model - DEBUG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84172777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://modeldeployment.us-ashburn-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.iad.amaaaaaawe6j4fqabusufajddpcyeusvyvzbqnxkazqj7qdkbe2p7al4k5ua\n"
     ]
    }
   ],
   "source": [
    "# Deploy and create an endpoint for the huggingface_pipeline_model\n",
    "\n",
    "huggingface_pipeline_model.deploy(\n",
    "    display_name=\"HuggingFace Pipeline Model For Text Summarization\",\n",
    "    deployment_log_group_id=\"ocid1.loggroup.oc1.iad.amaaaaaawe6j4fqaffwnle4a3vgrxnyr7tknflwlnsuq3tdzcwmmpiu5lxqa\",\n",
    "    deployment_access_log_id=\"ocid1.log.oc1.iad.amaaaaaawe6j4fqae5vfln65avtsdiv3j47mmpkjmnrarjmopyg3jb57ujfa\",\n",
    "    deployment_predict_log_id=\"ocid1.log.oc1.iad.amaaaaaawe6j4fqae5vfln65avtsdiv3j47mmpkjmnrarjmopyg3jb57ujfa\"\n",
    ")\n",
    "\n",
    "print(f\"Endpoint: {huggingface_pipeline_model.model_deployment.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669245c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "305038ea",
   "metadata": {},
   "source": [
    "# Prediction using MD Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25847c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': [{'summary_text': 'Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores .'}]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate prediction by invoking the deployed endpoint\n",
    "\n",
    "# The OCI SDK must be installed for this example to function properly.\n",
    "# Installation instructions can be found here: https://docs.oracle.com/en-us/iaas/Content/API/SDKDocs/pythonsdk.htm\n",
    "\n",
    "import requests\n",
    "import oci\n",
    "from oci.signer import Signer\n",
    "\n",
    "config = oci.config.from_file(profile_name='jiayuan') # replace with the location of your oci config file\n",
    "auth = Signer(\n",
    "  tenancy=config['tenancy'],\n",
    "  user=config['user'],\n",
    "  fingerprint=config['fingerprint'],\n",
    "  private_key_file_location=config['key_file'],\n",
    "  pass_phrase=config['pass_phrase'])\n",
    "\n",
    "endpoint = 'https://modeldeployment.us-ashburn-1.oci.customer-oci.com/ocid1.datasciencemodeldeployment.oc1.iad.amaaaaaawe6j4fqabusufajddpcyeusvyvzbqnxkazqj7qdkbe2p7al4k5ua/predict'\n",
    "body = \"Zoom interface is really simple and easy to conduct virtual meetings. It is very easy to share the Zoom link to join the video conference. And overall screen sharing quality is ok. Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores , for its cloud infrastructure deployments over the likes of Amazon, Microsoft, Google, and even IBM to build an enterprise grade experience for its product.\" # payload goes here\n",
    "headers = {} # header goes here\n",
    "\n",
    "requests.post(endpoint, json=body, auth=auth, headers=headers).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ec34713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zoom now claims to have 300 million meeting participants per day. It chose Oracle Corporation co-founded by Larry Ellison and headquartered in Redwood Shores .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = requests.post(endpoint, json=body, auth=auth, headers=headers).json()['prediction']\n",
    "pred[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035138c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ea294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed1ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef892f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040f1387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch110_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-pytorch110_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
